// test-local-model-sync.js
// Simple test to verify local model sync functionality

async function testOllamaConnection() {
  try {
    console.log('üîÑ Testing Ollama connection...');
    
    // Test Ollama API
    const response = await fetch('http://localhost:11434/api/tags');
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    const data = await response.json();
    console.log('‚úÖ Ollama connection successful!');
    console.log('üìä Available models:', data.models.length);
    
    data.models.forEach(model => {
      console.log(`  - ${model.name} (${model.details.parameter_size})`);
    });
    
    return {
      isConnected: true,
      models: data.models
    };
    
  } catch (error) {
    console.error('‚ùå Ollama connection failed:', error.message);
    return {
      isConnected: false,
      models: []
    };
  }
}

async function testWorkspaceStatus() {
  try {
    console.log('\nüîÑ Testing workspace status...');
    
    const response = await fetch('http://localhost:3003');
    
    if (!response.ok) {
      throw new Error(`HTTP error! status: ${response.status}`);
    }
    
    const html = await response.text();
    
    // Check for key indicators
    const hasNoModelsMessage = html.includes('No models available');
    const hasLocalModelsTab = html.includes('Local Models');
    
    console.log('üìä Workspace Status:');
    console.log(`  - No models message: ${hasNoModelsMessage ? '‚ùå' : '‚úÖ'}`);
    console.log(`  - Local models tab: ${hasLocalModelsTab ? '‚úÖ' : '‚ùå'}`);
    
    return {
      isOnline: true,
      hasNoModelsMessage,
      hasLocalModelsTab
    };
    
  } catch (error) {
    console.error('‚ùå Workspace connection failed:', error.message);
    return {
      isOnline: false,
      hasNoModelsMessage: true,
      hasLocalModelsTab: false
    };
  }
}

async function main() {
  console.log('üöÄ OmniPanel Local Model Integration Test\n');
  
  const ollamaStatus = await testOllamaConnection();
  const workspaceStatus = await testWorkspaceStatus();
  
  console.log('\nüìã Summary:');
  console.log('============');
  
  if (ollamaStatus.isConnected && ollamaStatus.models.length > 0) {
    console.log('‚úÖ Ollama is running with models available');
  } else {
    console.log('‚ùå Ollama issue detected');
  }
  
  if (workspaceStatus.isOnline && !workspaceStatus.hasNoModelsMessage) {
    console.log('‚úÖ Workspace shows models are available');
  } else {
    console.log('‚ùå Workspace still shows no models available');
  }
  
  console.log('\nüîß Diagnosis:');
  if (ollamaStatus.isConnected && ollamaStatus.models.length > 0 && workspaceStatus.hasNoModelsMessage) {
    console.log('‚ùå Local model sync is NOT working - models available but not detected');
    console.log('üîß Need to fix: LocalModelSyncProvider integration');
  } else if (!ollamaStatus.isConnected) {
    console.log('‚ùå Ollama not running or no models available');
  } else {
    console.log('‚úÖ Integration appears to be working');
  }
}

main().catch(console.error); 